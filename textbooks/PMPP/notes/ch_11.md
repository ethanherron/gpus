# Prefix sum (scan)

## Chapter Outline
- 11.1 Background
- 11.2 Parallel scan with the Kogge-Stone algorithm
- 11.3 Speed and work efficiency consideration
- 11.4 Parallel scan with the Brent-Kung algorithm
- 11.5 Coarsening for even more work efficiency
- 11.6 Segmented parallel scan for arbitrary-length inputs
- 11.7 Single-pass scan for memory access efficiency
- 11.8 Summary

## Introduction

Prefix sum (also known as scan) is a fundamental parallel pattern frequently used to parallelize seemingly sequential operations, such as resource allocation, work assignment, and polynomial evaluation. It plays a crucial role in massively parallel computing because any sequential section of an application can drastically limit overall performance, and many such sequential sections can be converted into parallel computation with parallel scan.

Prefix sum serves as a primitive operation in various parallel algorithms, including:
- Radix sort
- Quick sort
- String comparison
- Polynomial evaluation
- Solving recurrences
- Tree operations
- Stream compaction

This chapter also introduces an important concept in parallel computing: work efficiency, where some parallel algorithms can have higher complexity than sequential algorithms, leading to trade-offs between algorithm complexity and parallelization. As we'll see, a slight increase in algorithm complexity can make parallel scan run more slowly than sequential scan for large datasets, which is particularly important in the "big data" era.

## 11.1 Background

Mathematically, an **inclusive scan** operation takes a binary associative operator ⊕ and an input array of n elements [x₀, x₁, ..., xₙ₋₁], and returns the following output array:

[x₀, (x₀⊕x₁), ..., (x₀⊕x₁⊕...⊕xₙ₋₁)]

For example, if ⊕ is addition, an inclusive scan operation on the input array [3 1 7 0 4 1 6 3] would return [3, 3+1, 3+1+7, 3+1+7+0, ..., 3+1+7+0+4+1+6+3] = [3 4 11 11 15 16 22 25]. The name "inclusive" comes from the fact that each output element includes the effect of the corresponding input element.

### Applications of Inclusive Scan

We can illustrate applications for inclusive scan using a sausage-cutting example. Assume we have a 40-inch sausage to serve to eight people who have ordered different amounts: 3, 1, 7, 0, 4, 1, 6, and 3 inches.

- **Sequential approach**: Cut 3 inches for Person 0, then 1 inch for Person 1, and so on.
- **Parallel approach with inclusive scan**: Calculate all cutting points simultaneously based on each person's order.

Given the order input array [3 1 7 0 4 1 6 3], the inclusive scan returns [3 4 11 11 15 16 22 25], which represents all the cutting locations. With this information, all eight cuts can be made simultaneously or in any arbitrary sequence.

An **exclusive scan** operation is similar but slightly different:

[i, x₀, (x₀⊕x₁), ..., (x₀⊕x₁⊕...⊕xₙ₋₂)]

Each output element excludes the effect of the corresponding input element. The first output element is i (the identity value for operator ⊕), while the last output element only includes up to xₙ₋₂.

In our sausage example, an exclusive scan would return [0 3 4 11 11 15 16 22], which represents the beginning points of each cut section. This beginning point information is important in applications such as memory allocation, where allocated memory is returned via a pointer to its beginning.

Converting between inclusive and exclusive scan outputs is straightforward:
- From inclusive to exclusive: Shift all elements right and fill in the identity value for the 0th element
- From exclusive to inclusive: Shift all elements left and fill in the last element with the previous last element ⊕ the last input element

### Sequential Scan Implementation

Before exploring parallel algorithms, here's a sequential inclusive scan implementation:

```c
void sequential_scan(float *x, float *y, unsigned int N) {
    y[0] = x[0];
    for(unsigned int i = 1; i < N; ++i) {
        y[i] = y[i - 1] + x[i];
    }
}
```

The code initializes y[0] with x[0], then in each loop iteration adds one more input element to the previous output element to generate the next output element. The computational complexity of this sequential algorithm is O(N).

## 11.2 Parallel scan with the Kogge-Stone algorithm

A naive approach to parallel scan might involve assigning each thread to compute one output element by performing a sequential reduction. However, this approach would not improve execution time over sequential scan, as calculating the last output element still takes n steps. Additionally, the total computation cost would increase to O(N²), making this approach inefficient.

A better approach adapts the Kogge-Stone algorithm, originally invented for designing fast adder circuits in the 1970s. This algorithm effectively shares partial sums across reduction trees for different output elements.

The Kogge-Stone algorithm works as follows:
1. Start with an array XY containing input elements
2. Iteratively evolve array contents through multiple passes
3. After k iterations, XY[i] contains the sum of up to 2ᵏ input elements at and before that location

For example, with a 16-element input:
- Before algorithm begins: XY[i] contains input element xᵢ
- After first iteration: XY[i] contains xᵢ₋₁+xᵢ
- After second iteration: XY[i] contains xᵢ₋₃+xᵢ₋₂+xᵢ₋₁+xᵢ

### Implementation of Kogge-Stone Scan

```cuda
__global__ void Kogge_Stone_scan_kernel(float *X, float *Y, unsigned int N){
    __shared__ float XY[SECTION_SIZE];
    unsigned int i = blockIdx.x*blockDim.x + threadIdx.x;
    if(i < N) {
        XY[threadIdx.x] = X[i];
    } else {
        XY[threadIdx.x] = 0.0f;
    }
    for(unsigned int stride = 1; stride < blockDim.x; stride *= 2) {
        __syncthreads();
        float temp;
        if(threadIdx.x >= stride)
            temp = XY[threadIdx.x] + XY[threadIdx.x-stride];
        __syncthreads();
        if(threadIdx.x >= stride)
            XY[threadIdx.x] = temp;
    }
    if(i < N) {
        Y[i] = XY[threadIdx.x];
    }
}
```

The implementation:
1. Loads input elements from global memory into shared memory
2. Performs iterative calculations with increasing stride values
3. Uses a temporary variable and barrier synchronization to avoid race conditions
4. Writes final results back to global memory

### Write-After-Read Race Condition

A critical aspect of this algorithm is handling the write-after-read data dependence. Each active thread adds the XY value at its own position and that at another position. If a thread writes to its output position before another thread has read the old value at that position, it can corrupt the other thread's calculation.

For example, in the second iteration:
- Thread 6 needs to add the old value of XY[4] (x₃+x₄) and XY[6] (x₅+x₆)
- If thread 4 stores its new value (x₁+x₂+x₃+x₄) into XY[4] too early, thread 6 could use the wrong value

This race condition is overcome using:
1. A temporary variable to store intermediate results before writing to shared memory
2. A barrier synchronization to ensure all threads complete their reads before any writes occur

### Converting to Exclusive Scan

To convert an inclusive scan kernel to an exclusive scan kernel, we modify how elements are loaded:

```cuda
if(threadIdx.x == 0) {
    XY[threadIdx.x] = 0.0f;
} else if(i < N) {
    XY[threadIdx.x] = X[i-1];
} else {
    XY[threadIdx.x] = 0.0f;
}
```

This modification loads 0 into XY[0] and X[i-1] into XY[threadIdx.x], effectively shifting the result by one position.

## 11.3 Speed and work efficiency consideration

Work efficiency refers to how close the amount of work performed by an algorithm is to the minimum amount needed for the computation. For scan operations:
- Sequential algorithm requires N-1 additions (O(N))
- Naive parallel algorithm performs N(N-1)/2 additions (O(N²))
- Kogge-Stone algorithm performs N·log₂(N)-(N-1) operations (O(N·log₂(N)))

While Kogge-Stone is more efficient than the naive parallel approach, it still performs more work than the sequential algorithm. For 512 elements, it does approximately eight times more work, and this ratio increases with larger N.

### Steps vs. Work Trade-off

Despite performing more total work, Kogge-Stone can execute in fewer steps due to parallel execution:
- Sequential code executes N iterations
- Kogge-Stone executes log₂(N) iterations with sufficient parallelism

With unlimited execution resources, the reduction in steps would be approximately N/log₂(N). For N=512, this is about 56.9x fewer steps.

In practice, the performance depends on available hardware resources:
- With P execution units, Kogge-Stone takes approximately (N·log₂(N))/P steps
- If P equals N, the kernel needs log₂(N) steps
- With limited resources (P < N), the kernel may take more steps than the theoretical minimum

This creates two potential issues:
1. If hardware resources are insufficient, the parallel algorithm could be slower than sequential
2. The extra work consumes additional energy, making it less suitable for power-constrained environments

Kogge-Stone's strength is achieving good execution speed with sufficient hardware resources, typically used for sections with modest element counts (512 or 1024). It has minimal control divergence and can be efficiently implemented with shuffle instructions within warps in newer GPU architectures.

## 11.4 Parallel scan with the Brent-Kung algorithm

While the Kogge-Stone kernel is conceptually simple, its work efficiency is quite low for many practical applications. By inspecting the algorithm, we can see opportunities for further sharing of intermediate results, but this requires strategically calculating and distributing these results to different threads.

The Brent-Kung algorithm, originally designed for adder circuits in 1979, offers a more work-efficient approach to parallel scan. Like Kogge-Stone, it's based on the observation that the fastest way to produce sum values is a reduction tree, which can generate the sum for N values in log₂(N) time units with sufficient execution resources.

### Algorithm Structure

The Brent-Kung algorithm consists of two phases:
1. **Reduction Tree Phase**: Produces the sum of all elements with minimal operations
2. **Reverse Tree Phase**: Distributes partial sums to complete results for all positions

#### Reduction Tree Phase

In the reduction tree phase for a 16-element input:
- First step: Odd-indexed elements (1, 3, 5, 7, 9, 11, 13, 15) are updated with their own value plus the value at position-1
- Second step: Elements at indices of form 4n-1 (3, 7, 11, 15) are updated
- Third step: Elements at indices of form 8n-1 (7, 15) are updated
- Fourth step: Only element 15 is updated

This phase performs a total of 8+4+2+1=15 operations. For N elements, the total is N-1 operations, which is optimal for finding the total sum.

#### Reverse Tree Phase

After the reduction phase, certain positions (0, 1, 3, 7, 15) already contain their final scan values. The reverse tree distributes partial sums to other positions in a way that minimizes operations:

1. First level: Distributes from position 7 to position 11 (stride=4)
2. Second level: Distributes from positions 3, 7, 11 to positions 5, 9, 13 (stride=2)
3. Third level: Distributes from odd positions to adjacent even positions (stride=1)

This phase completes the results for all positions with minimal additional operations.

### Implementation

The Brent-Kung kernel implementation requires careful index calculations to manage both phases efficiently:

```cuda
__global__ void Brent_Kung_scan_kernel(float *X, float *Y, unsigned int N) {
    __shared__ float XY[SECTION_SIZE];
    unsigned int i = 2*blockIdx.x*blockDim.x + threadIdx.x;
    if(i < N) XY[threadIdx.x] = X[i];
    if(i + blockDim.x < N) XY[threadIdx.x + blockDim.x] = X[i + blockDim.x];
    
    // Reduction tree phase
    for(unsigned int stride = 1; stride <= blockDim.x; stride *= 2) {
        __syncthreads();
        unsigned int index = (threadIdx.x + 1)*2*stride - 1;
        if(index < SECTION_SIZE) {
            XY[index] += XY[index - stride];
        }
    }
    
    // Reverse tree phase
    for (int stride = SECTION_SIZE/4; stride > 0; stride /= 2) {
        __syncthreads();
        unsigned int index = (threadIdx.x + 1)*stride*2 - 1;
        if(index + stride < SECTION_SIZE) {
            XY[index + stride] += XY[index];
        }
    }
    
    __syncthreads();
    if (i < N) Y[i] = XY[threadIdx.x];
    if (i + blockDim.x < N) Y[i + blockDim.x] = XY[threadIdx.x + blockDim.x];
}
```

Key features of this implementation:
1. Each thread is responsible for two input elements, allowing scan sections of up to 2048 elements with 1024 threads
2. Complex index calculations ensure active threads operate on appropriate array locations
3. The reduction and reverse tree phases together minimize the total number of operations

### Work Efficiency Analysis

The total number of operations in Brent-Kung is:
- Reduction tree: N-1 operations
- Reverse tree: N-1-log₂(N) operations
- Total: 2N-2-log₂(N) operations, which is O(N)

This makes Brent-Kung significantly more work-efficient than Kogge-Stone's O(N·log₂(N)) operations. As input sections grow larger, Brent-Kung never performs more than twice the operations of the sequential algorithm.

### Performance Considerations

Despite its theoretical work efficiency, Brent-Kung's practical advantage may be limited on CUDA devices:
- Control divergence when the number of active threads drops below warp size
- Inactive threads still consume execution resources due to SIMD architecture
- The reverse tree phase adds additional steps, potentially doubling execution time

For example, processing 1024 input elements with 32 execution units:
- Brent-Kung might take approximately 73.6 steps (including divergence overhead)
- This yields a 14× speedup over sequential execution
- Compared to Kogge-Stone's 320 steps and 3.2× speedup

The choice between algorithms depends on available execution resources and latency characteristics of the target hardware.

## 11.5 Coarsening for even more work efficiency

Thread coarsening can further improve work efficiency by addressing the overhead of parallelization, which includes hardware underutilization and synchronization costs. For scan operations, coarsening also helps mitigate the reduced work efficiency of parallel scan algorithms.

The key idea is to have each thread perform sequential work on a larger portion of data, thereby serializing the work in a controlled manner that improves efficiency.

### Three-Phase Coarsened Scan

A coarsened scan algorithm divides execution into three phases:

1. **Phase 1: Sequential Scan**
   - Each thread performs a sequential scan on its own subsection
   - For example, with 4 threads and 16 elements, each thread processes 4 elements
   - Thread 0 processes (2,1,3,1) → (2,3,6,7)
   - Thread 1 processes (0,4,1,2) → (0,4,5,7)
   - And so on

2. **Phase 2: Parallel Scan on Last Elements**
   - All threads collaborate to perform scan on the last elements of each subsection
   - This can use Kogge-Stone or Brent-Kung algorithm
   - For example, process (7,7,6,11) → (7,14,20,31)

3. **Phase 3: Final Update**
   - Each thread adds the new value of its predecessor's last element to its elements
   - Thread 1 adds 7 to (0,4,5) → (7,11,12)
   - The last element of each subsection doesn't need updating

### Implementation Considerations

To implement this efficiently:
- Use shared memory to improve memory coalescing
- Initially, all threads collaborate to load input into shared memory in a coalesced pattern
- For phase 2, element mapping must be modified since elements are stride-distance apart
- The maximal section size is limited by shared memory capacity, not thread count

### Work Efficiency Analysis

For N input elements using T threads, the work performed is:
- Phase 1: N-T operations (sequential scan within subsections)
- Phase 2: T·log₂(T) operations (parallel scan on subsection sums)
- Phase 3: N-T operations (final updating)
- Total: 2N-2T+T·log₂(T) operations

With sufficient hardware resources (P execution units), execution time approximates to (N-T+T·log₂(T)+N-T)/P steps.

For example, with 1024 elements, 64 threads, and 32 execution units, we can expect about 72 steps, which is more efficient than both Kogge-Stone and Brent-Kung approaches.

## 11.6 Segmented parallel scan for arbitrary-length inputs

When dealing with large datasets (millions or billions of elements), we need a hierarchical approach that extends scan algorithms to arbitrary input lengths. The basic approach divides the input into sections that can be processed by individual thread blocks, then combines these sectional results.

### Hierarchical Scan Approach

The hierarchical scan operates in three steps:

1. **Local Scan**: Partition input into sections (scan blocks) that fit in shared memory
   - Each thread block performs scan on its section independently
   - After this step, each element contains accumulated values from its section only

2. **Block Sum Scan**: Collect the sum from each section into an array and scan it
   - The last element of each scan block contains the section's total sum
   - Scanning these values produces cumulative sums across all preceding sections

3. **Final Combination**: Add appropriate block sum to each element in each section
   - Each element needs the sum of all preceding sections added to it
   - This completes the scan operation on the entire input

### Example

For an input of 16 elements divided into 4 scan blocks:

1. After local scan:
   - Scan block 0: (2,3,6,7)
   - Scan block 1: (0,4,5,7)
   - Scan block 2: (0,3,4,6)
   - Scan block 3: (0,2,5,11)

2. Collect last elements and scan:
   - S = [7,7,6,11] → [7,14,20,31]

3. Add S[blockIdx-1] to each element:
   - Scan block 1: (0+7,4+7,5+7,7+7) = (7,11,12,14)
   - Scan block 2: (0+14,3+14,4+14,6+14) = (14,17,18,20)
   - Scan block 3: (0+20,2+20,5+20,11+20) = (20,22,25,31)

### Implementation

The segmented scan can be implemented with three kernels:

1. **First Kernel**: Standard scan on each section
   - Add code to store last element to global array S

```cuda
// At end of first kernel
if (threadIdx.x == blockDim.x-1) {
    S[blockIdx.x] = XY[threadIdx.x];
}
```

2. **Second Kernel**: Scan the S array
   - Single thread block processes entire S array

3. **Third Kernel**: Add appropriate S value to each element
   - Each block's threads add previous scan block's final sum

```cuda
__global__ void add_scan_block_sums(float *Y, float *S, unsigned int N) {
    unsigned int i = blockIdx.x*blockDim.x + threadIdx.x;
    if (i < N && blockIdx.x > 0) {
        Y[i] += S[blockIdx.x-1];
    }
}
```

The similarity between this approach and carry look-ahead in hardware adders is notable - both use hierarchical processing to efficiently propagate values through a large system.

## 11.7 Single-pass scan for memory access efficiency

The three-kernel segmented scan approach involves storing and reloading partially scanned results from global memory, which can significantly impact performance. To avoid this overhead, we can use a single-pass or "domino-style" scan algorithm.

### Stream-Based Scan Algorithm

The key insight of stream-based scan is that global scan doesn't require grid-wide synchronization - it can be performed in a domino fashion where:
- Scan block i processes its data
- Waits for scan block i-1 to pass its sum value
- Adds received sum to its own sum and passes result to scan block i+1
- Completes its output by adding received sum to all its elements

This approach eliminates the need for separate kernels and additional global memory traffic, as all three phases of the segmented scan occur within a single kernel.

### Adjacent Block Synchronization

To implement domino-style scan, we need a mechanism for adjacent thread blocks to synchronize and exchange data. This is achieved using atomic operations:

```cuda
// Leader thread in each block executes this code
// Wait until predecessor block signals it's done
while (atomicAdd(&flags[bid], 0) != 1);

// Load partial sum from predecessor
float previous_sum = scan_value[bid];
// Add to local sum and store for next block
scan_value[bid+1] = previous_sum + local_sum;

// Ensure memory operations complete before setting flag
__threadfence();
// Signal next block
atomicAdd(&flags[bid+1], 1);

__syncthreads();
```

Key elements of this implementation:
1. Each block waits for its predecessor's flag before continuing
2. Memory fence operations ensure correct ordering of memory operations
3. Atomic operations provide necessary synchronization guarantees

Most global memory traffic in this process will be handled by L2 cache in recent GPU architectures, and computation in other blocks can overlap with these operations, improving overall efficiency.

### Preventing Deadlocks with Dynamic Block Index Assignment

A challenge with domino-style algorithms is that GPU thread blocks may not be scheduled linearly according to their indices. If block i is scheduled before block i-1, deadlock can occur as block i waits indefinitely for data from block i-1.

This is solved with dynamic block index assignment:

```cuda
__shared__ int bid_s;
if (threadIdx.x == 0) {
    bid_s = atomicAdd(blockCounter, 1);
}
__syncthreads();
int bid = bid_s;
```

This technique:
- Decouples thread block execution order from logical processing order
- Guarantees if a block obtains index i, a block with index i-1 has already been scheduled
- Prevents potential deadlocks that could occur with static block indexing

## 11.8 Summary

Prefix sum (scan) is an important parallel pattern that enables parallelization of seemingly sequential operations. It plays a critical role in eliminating sequential bottlenecks in many applications by converting mathematical recurrences into parallel computations.

This chapter explored several key aspects of parallel scan:

1. **Algorithm Efficiency Trade-offs**:
   - Sequential scan: O(N) operations, simple but sequential
   - Kogge-Stone scan: O(N·log₂N) operations, fast with sufficient resources but not work-efficient
   - Brent-Kung scan: O(N) operations, work-efficient but potentially slower with ample resources
   - Thread coarsening: Further improves work efficiency by combining sequential and parallel approaches

2. **Hierarchical Approaches for Large Datasets**:
   - Three-kernel segmented scan approach for arbitrary-length inputs
   - Single-pass, domino-style scan for improved memory access efficiency
   - Adjacent block synchronization techniques using atomic operations

3. **Implementation Considerations**:
   - Race condition management with temporary variables and synchronization
   - Memory coalescing through shared memory usage
   - Deadlock prevention with dynamic block index assignment
   - Careful thread-to-data index mapping to minimize control divergence

The choice of scan algorithm depends on specific hardware characteristics and application needs:
- Kogge-Stone works well for modest-sized blocks with abundant execution resources
- Brent-Kung is preferable in energy-constrained environments or for larger datasets
- Coarsened scan provides a balance between parallelism and efficiency
- Single-pass approaches optimize overall memory efficiency for large inputs

For most users, leveraging existing parallel scan libraries like Thrust is recommended over implementing custom scan kernels from scratch. Nevertheless, understanding these algorithms provides valuable insights into the trade-offs involved in optimizing parallel patterns.



